---
title: Gestos en Unity
description: Obtenga información sobre cómo realizar una acción en Unity en Unity con la entrada de gestos de mano mediante XR y las API de eje y de botón comunes.
author: hferrone
ms.author: alexturn
ms.date: 12/1/2020
ms.topic: article
keywords: gestos, Unity, miras, entrada, auriculares de realidad mixta, auriculares de la realidad mixta de Windows, auriculares de realidad virtual, MRTK, kit de herramientas de realidad mixta
ms.openlocfilehash: 44c42abdd4628cacd6af334a916fb725da8bb022
ms.sourcegitcommit: d3a3b4f13b3728cfdd4d43035c806c0791d3f2fe
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 01/20/2021
ms.locfileid: "98583898"
---
# <a name="gestures-in-unity"></a><span data-ttu-id="6966b-104">Gestos en Unity</span><span class="sxs-lookup"><span data-stu-id="6966b-104">Gestures in Unity</span></span>

<span data-ttu-id="6966b-105">Hay dos formas clave de tomar medidas en su [mirada en Unity](gaze-in-unity.md), [gestos de mano](../../design/gaze-and-commit.md#composite-gestures) y [controladores de movimiento](../../design/motion-controllers.md) en HoloLens y HMDs envolventes.</span><span class="sxs-lookup"><span data-stu-id="6966b-105">There are two key ways to take action on your [gaze in Unity](gaze-in-unity.md), [hand gestures](../../design/gaze-and-commit.md#composite-gestures) and [motion controllers](../../design/motion-controllers.md) in HoloLens and Immersive HMD.</span></span> <span data-ttu-id="6966b-106">Puede tener acceso a los datos de los dos orígenes de entrada espacial a través de las mismas API en Unity.</span><span class="sxs-lookup"><span data-stu-id="6966b-106">You access the data for both sources of spatial input through the same APIs in Unity.</span></span>

<span data-ttu-id="6966b-107">Unity proporciona dos maneras principales de tener acceso a los datos de entrada espacial para Windows Mixed Reality.</span><span class="sxs-lookup"><span data-stu-id="6966b-107">Unity provides two primary ways to access spatial input data for Windows Mixed Reality.</span></span> <span data-ttu-id="6966b-108">Las API de *Input. GetButton/Input. GetAxis* comunes funcionan en varios SDK de Unity XR, mientras que la API *InteractionManager/GestureRecognizer* específica de Windows Mixed Reality expone el conjunto completo de datos de entrada espacial.</span><span class="sxs-lookup"><span data-stu-id="6966b-108">The common *Input.GetButton/Input.GetAxis* APIs work across multiple Unity XR SDKs, while the *InteractionManager/GestureRecognizer* API specific to Windows Mixed Reality exposes the full set of spatial input data.</span></span>

## <a name="high-level-composite-gesture-apis-gesturerecognizer"></a><span data-ttu-id="6966b-109">API de gesto compuesto de alto nivel (GestureRecognizer)</span><span class="sxs-lookup"><span data-stu-id="6966b-109">High-level composite gesture APIs (GestureRecognizer)</span></span>

<span data-ttu-id="6966b-110">**Espacio de nombres:** *UnityEngine. XR. WSA. Input*</span><span class="sxs-lookup"><span data-stu-id="6966b-110">**Namespace:** *UnityEngine.XR.WSA.Input*</span></span><br>
<span data-ttu-id="6966b-111">**Tipos**: *GestureRecognizer*, *GestureSettings*, *InteractionSourceKind*</span><span class="sxs-lookup"><span data-stu-id="6966b-111">**Types**: *GestureRecognizer*, *GestureSettings*, *InteractionSourceKind*</span></span>

<span data-ttu-id="6966b-112">La aplicación también puede reconocer gestos compuestos de nivel superior para orígenes de entrada espaciales, puntear, retener, manipular y gestos de navegación.</span><span class="sxs-lookup"><span data-stu-id="6966b-112">Your app can also recognize higher-level composite gestures for spatial input sources, Tap, Hold, Manipulation, and Navigation gestures.</span></span> <span data-ttu-id="6966b-113">Puede reconocer estos gestos compuestos a través de las [manos](../../design/gaze-and-commit.md#composite-gestures) y [los controladores de movimiento](../../design/motion-controllers.md) mediante GestureRecognizer.</span><span class="sxs-lookup"><span data-stu-id="6966b-113">You can recognize these composite gestures across both [hands](../../design/gaze-and-commit.md#composite-gestures) and [motion controllers](../../design/motion-controllers.md) using the GestureRecognizer.</span></span>

<span data-ttu-id="6966b-114">Cada evento de gesto en el GestureRecognizer proporciona el SourceKind para la entrada, así como el rayo del cabezal de destino en el momento del evento.</span><span class="sxs-lookup"><span data-stu-id="6966b-114">Each Gesture event on the GestureRecognizer provides the SourceKind for the input as well as the targeting head ray at the time of the event.</span></span> <span data-ttu-id="6966b-115">Algunos eventos proporcionan información adicional específica del contexto.</span><span class="sxs-lookup"><span data-stu-id="6966b-115">Some events provide additional context-specific information.</span></span>

<span data-ttu-id="6966b-116">Solo se requieren algunos pasos para capturar gestos mediante un reconocedor de gestos:</span><span class="sxs-lookup"><span data-stu-id="6966b-116">There are only a few steps required to capture gestures using a Gesture Recognizer:</span></span>
1. <span data-ttu-id="6966b-117">Crear un nuevo reconocedor de gestos</span><span class="sxs-lookup"><span data-stu-id="6966b-117">Create a new Gesture Recognizer</span></span>
2. <span data-ttu-id="6966b-118">Especificar los gestos que se van a inspeccionar</span><span class="sxs-lookup"><span data-stu-id="6966b-118">Specify which gestures to watch for</span></span>
3. <span data-ttu-id="6966b-119">Suscripción a eventos para esos gestos</span><span class="sxs-lookup"><span data-stu-id="6966b-119">Subscribe to events for those gestures</span></span>
4. <span data-ttu-id="6966b-120">Iniciar la captura de gestos</span><span class="sxs-lookup"><span data-stu-id="6966b-120">Start capturing gestures</span></span>

### <a name="create-a-new-gesture-recognizer"></a><span data-ttu-id="6966b-121">Crear un nuevo reconocedor de gestos</span><span class="sxs-lookup"><span data-stu-id="6966b-121">Create a new Gesture Recognizer</span></span>

<span data-ttu-id="6966b-122">Para usar *GestureRecognizer*, debe haber creado un *GestureRecognizer*:</span><span class="sxs-lookup"><span data-stu-id="6966b-122">To use the *GestureRecognizer*, you must have created a *GestureRecognizer*:</span></span>

```cs
GestureRecognizer recognizer = new GestureRecognizer();
```

### <a name="specify-which-gestures-to-watch-for"></a><span data-ttu-id="6966b-123">Especificar los gestos que se van a inspeccionar</span><span class="sxs-lookup"><span data-stu-id="6966b-123">Specify which gestures to watch for</span></span>

<span data-ttu-id="6966b-124">Especifique los gestos que le interesan a través de *SetRecognizableGestures ()*:</span><span class="sxs-lookup"><span data-stu-id="6966b-124">Specify which gestures you're interested in via *SetRecognizableGestures()*:</span></span>

```cs
recognizer.SetRecognizableGestures(GestureSettings.Tap | GestureSettings.Hold);
```

### <a name="subscribe-to-events-for-those-gestures"></a><span data-ttu-id="6966b-125">Suscripción a eventos para esos gestos</span><span class="sxs-lookup"><span data-stu-id="6966b-125">Subscribe to events for those gestures</span></span>

<span data-ttu-id="6966b-126">Suscríbase a eventos para los gestos que le interesan.</span><span class="sxs-lookup"><span data-stu-id="6966b-126">Subscribe to events for the gestures you're interested in.</span></span>

```cs
void Start()
{
    recognizer.Tapped += GestureRecognizer_Tapped;
    recognizer.HoldStarted += GestureRecognizer_HoldStarted;
    recognizer.HoldCompleted += GestureRecognizer_HoldCompleted;
    recognizer.HoldCanceled += GestureRecognizer_HoldCanceled;
}
```

>[!NOTE]
><span data-ttu-id="6966b-127">Los gestos de navegación y manipulación se excluyen mutuamente en una instancia de un *GestureRecognizer*.</span><span class="sxs-lookup"><span data-stu-id="6966b-127">Navigation and Manipulation gestures are mutually exclusive on an instance of a *GestureRecognizer*.</span></span>

### <a name="start-capturing-gestures"></a><span data-ttu-id="6966b-128">Iniciar la captura de gestos</span><span class="sxs-lookup"><span data-stu-id="6966b-128">Start capturing gestures</span></span>

<span data-ttu-id="6966b-129">De forma predeterminada, un *GestureRecognizer* no supervisa la entrada hasta que se llama a *StartCapturingGestures ()* .</span><span class="sxs-lookup"><span data-stu-id="6966b-129">By default, a *GestureRecognizer* doesn't monitor input until *StartCapturingGestures()* is called.</span></span> <span data-ttu-id="6966b-130">Es posible que se genere un evento de gesto después de que se llame a *StopCapturingGestures ()* si la entrada se realizó antes que el marco en el que se procesó *StopCapturingGestures ()* .</span><span class="sxs-lookup"><span data-stu-id="6966b-130">It's possible that a gesture event may be generated after *StopCapturingGestures()* is called if input was performed before the frame where *StopCapturingGestures()* was processed.</span></span> <span data-ttu-id="6966b-131">El *GestureRecognizer* recordará si está activado o desactivado durante el fotograma anterior en el que se produjo realmente el gesto, por lo que es confiable iniciar y detener la supervisión de gestos según el destino de la mirada a este fotograma.</span><span class="sxs-lookup"><span data-stu-id="6966b-131">The *GestureRecognizer* will remember whether it was on or off during the previous frame in which the gesture actually occurred, and so it's reliable to start and stop gesture monitoring based on this frame's gaze targeting.</span></span>

```cs
recognizer.StartCapturingGestures();
```

### <a name="stop-capturing-gestures"></a><span data-ttu-id="6966b-132">Detener captura de movimientos</span><span class="sxs-lookup"><span data-stu-id="6966b-132">Stop capturing gestures</span></span>

<span data-ttu-id="6966b-133">Para detener el reconocimiento de gestos:</span><span class="sxs-lookup"><span data-stu-id="6966b-133">To stop gesture recognition:</span></span>

```cs
recognizer.StopCapturingGestures();
```

### <a name="removing-a-gesture-recognizer"></a><span data-ttu-id="6966b-134">Quitar un reconocedor de gestos</span><span class="sxs-lookup"><span data-stu-id="6966b-134">Removing a gesture recognizer</span></span>

<span data-ttu-id="6966b-135">Recuerde cancelar la suscripción a los eventos suscritos antes de destruir un objeto *GestureRecognizer* .</span><span class="sxs-lookup"><span data-stu-id="6966b-135">Remember to unsubscribe from subscribed events before destroying a *GestureRecognizer* object.</span></span>

```cs
void OnDestroy()
{
    recognizer.Tapped -= GestureRecognizer_Tapped;
    recognizer.HoldStarted -= GestureRecognizer_HoldStarted;
    recognizer.HoldCompleted -= GestureRecognizer_HoldCompleted;
    recognizer.HoldCanceled -= GestureRecognizer_HoldCanceled;
}
```

## <a name="rendering-the-motion-controller-model-in-unity"></a><span data-ttu-id="6966b-136">Representación del modelo de controlador de movimiento en Unity</span><span class="sxs-lookup"><span data-stu-id="6966b-136">Rendering the motion controller model in Unity</span></span>

<span data-ttu-id="6966b-137">![Modelo de controlador de movimiento y teleportabilidad](images/motioncontrollertest-teleport-1000px.png)</span><span class="sxs-lookup"><span data-stu-id="6966b-137">![Motion Controller model and teleportation](images/motioncontrollertest-teleport-1000px.png)</span></span><br>
<span data-ttu-id="6966b-138">*Modelo de controlador de movimiento y teleportabilidad*</span><span class="sxs-lookup"><span data-stu-id="6966b-138">*Motion controller model and teleportation*</span></span>

<span data-ttu-id="6966b-139">Para representar los controladores de movimiento en la aplicación que coincidan con las controladoras físicas que están manteniendo los usuarios y articular a medida que se presionan varios botones, puede usar **MotionController recurso prefabricado** en el [Kit de herramientas de realidad mixta](https://github.com/Microsoft/MixedRealityToolkit-Unity/).</span><span class="sxs-lookup"><span data-stu-id="6966b-139">To render motion controllers in your app that match the physical controllers your users are holding and articulate as various buttons are pressed, you can use the **MotionController prefab** in the [Mixed Reality Toolkit](https://github.com/Microsoft/MixedRealityToolkit-Unity/).</span></span>  <span data-ttu-id="6966b-140">Este recurso prefabricado carga dinámicamente el modelo de glTF correcto en tiempo de ejecución desde el controlador de controlador de movimiento instalado del sistema.</span><span class="sxs-lookup"><span data-stu-id="6966b-140">This prefab dynamically loads the correct glTF model at runtime from the system's installed motion controller driver.</span></span>  <span data-ttu-id="6966b-141">Es importante cargar estos modelos dinámicamente en lugar de importarlos manualmente en el editor, de modo que la aplicación muestre modelos 3D físicamente precisos para cualquier controlador actual y futuro que puedan tener los usuarios.</span><span class="sxs-lookup"><span data-stu-id="6966b-141">It's important to load these models dynamically rather than importing them manually in the editor, so that your app will show physically accurate 3D models for any current and future controllers your users may have.</span></span>

1. <span data-ttu-id="6966b-142">Siga las instrucciones [Introducción](https://github.com/Microsoft/MixedRealityToolkit-Unity/blob/htk_release/GettingStarted.md) para descargar el kit de herramientas de realidad mixta y agréguelo al proyecto de Unity.</span><span class="sxs-lookup"><span data-stu-id="6966b-142">Follow the [Getting Started](https://github.com/Microsoft/MixedRealityToolkit-Unity/blob/htk_release/GettingStarted.md) instructions to download the Mixed Reality Toolkit and add it to your Unity project.</span></span>
2. <span data-ttu-id="6966b-143">Si ha reemplazado la cámara con el recurso prefabricado de *MixedRealityCameraParent* como parte de los pasos introducción, está listo para empezar.</span><span class="sxs-lookup"><span data-stu-id="6966b-143">If you replaced your camera with the *MixedRealityCameraParent* prefab as part of the Getting Started steps, you're good to go!</span></span>  <span data-ttu-id="6966b-144">Ese recurso prefabricado incluye la representación del controlador de movimiento.</span><span class="sxs-lookup"><span data-stu-id="6966b-144">That prefab includes motion controller rendering.</span></span>  <span data-ttu-id="6966b-145">En caso contrario, agregue *assets/HoloToolkit/INPUT/Prefabs/MotionControllers. recurso prefabricado* a la escena desde el panel Proyecto.</span><span class="sxs-lookup"><span data-stu-id="6966b-145">Otherwise, add *Assets/HoloToolkit/Input/Prefabs/MotionControllers.prefab* into your scene from the Project pane.</span></span>  <span data-ttu-id="6966b-146">Querrá agregar ese recurso prefabricado como elemento secundario del objeto primario que usa para mover la cámara cuando el usuario teletransporta dentro de la escena, de modo que los controladores entren junto con el usuario.</span><span class="sxs-lookup"><span data-stu-id="6966b-146">You'll want to add that prefab as a child of whatever parent object you use to move the camera around when the user teleports within your scene, so that the controllers come along with the user.</span></span>  <span data-ttu-id="6966b-147">Si la aplicación no implica teletransportarse, solo tiene que agregar el recurso prefabricado en la raíz de la escena.</span><span class="sxs-lookup"><span data-stu-id="6966b-147">If your app doesn't involve teleporting, just add the prefab at the root of your scene.</span></span>

## <a name="throwing-objects"></a><span data-ttu-id="6966b-148">Producir objetos</span><span class="sxs-lookup"><span data-stu-id="6966b-148">Throwing objects</span></span>

<span data-ttu-id="6966b-149">Lanzar objetos en realidad virtual es un problema más difícil de lo que puede parecer al principio.</span><span class="sxs-lookup"><span data-stu-id="6966b-149">Throwing objects in virtual reality is a harder problem than it may at first seem.</span></span> <span data-ttu-id="6966b-150">Al igual que con la mayoría de las interacciones basadas físicamente, al iniciar el juego funciona de forma inesperada, es evidente de inmediato e interrumpe la inmersión.</span><span class="sxs-lookup"><span data-stu-id="6966b-150">As with most physically based interactions, when throwing in game acts in an unexpected way, it's immediately obvious and breaks immersion.</span></span> <span data-ttu-id="6966b-151">Hemos dedicado mucho tiempo a pensar en el modo de representar un comportamiento de lanzamiento que se ha corregido físicamente y han llegado algunas directrices, habilitadas a través de las actualizaciones de nuestra plataforma, que nos gustaría compartir con usted.</span><span class="sxs-lookup"><span data-stu-id="6966b-151">We've spent some time thinking deeply about how to represent a physically correct throwing behavior, and have come up with a few guidelines, enabled through updates to our platform, that we would like to share with you.</span></span>

<span data-ttu-id="6966b-152">Puede encontrar un ejemplo de cómo se recomienda implementar el lanzamiento [aquí](https://github.com/keluecke/MixedRealityToolkit-Unity/blob/master/External/Unitypackages/ThrowingStarter.unitypackage).</span><span class="sxs-lookup"><span data-stu-id="6966b-152">You can find an example of how we recommend to implement throwing [here](https://github.com/keluecke/MixedRealityToolkit-Unity/blob/master/External/Unitypackages/ThrowingStarter.unitypackage).</span></span> <span data-ttu-id="6966b-153">Este ejemplo sigue estas cuatro instrucciones:</span><span class="sxs-lookup"><span data-stu-id="6966b-153">This sample follows these four guidelines:</span></span>
* <span data-ttu-id="6966b-154">**Use la *velocidad* del controlador en lugar de la posición**.</span><span class="sxs-lookup"><span data-stu-id="6966b-154">**Use the controller’s *velocity* instead of position**.</span></span> <span data-ttu-id="6966b-155">En la actualización de noviembre de Windows, se presentó un cambio de comportamiento en el [Estado de seguimiento posicional ' ' aproximado](../../design/motion-controllers.md#controller-tracking-state)' '.</span><span class="sxs-lookup"><span data-stu-id="6966b-155">In the November update to Windows, we introduced a change in behavior when in the [''Approximate'' positional tracking state](../../design/motion-controllers.md#controller-tracking-state).</span></span> <span data-ttu-id="6966b-156">Cuando se encuentra en este estado, se seguirá informando de la información de velocidad de la controladora mientras creemos su alta precisión, que suele ser mayor que la posición es una precisión alta.</span><span class="sxs-lookup"><span data-stu-id="6966b-156">When in this state, velocity information about the controller will continue to be reported for as long as we believe its high accuracy, which is often longer than position remains high accuracy.</span></span>
* <span data-ttu-id="6966b-157">**Incorpore la *velocidad angular* del controlador**.</span><span class="sxs-lookup"><span data-stu-id="6966b-157">**Incorporate the *angular velocity* of the controller**.</span></span> <span data-ttu-id="6966b-158">Esta lógica está contenida en el `throwing.cs` archivo en el `GetThrownObjectVelAngVel` método estático, dentro del paquete vinculado anteriormente:</span><span class="sxs-lookup"><span data-stu-id="6966b-158">This logic is all contained in the `throwing.cs` file in the `GetThrownObjectVelAngVel` static method, within the package linked above:</span></span>
   1. <span data-ttu-id="6966b-159">A medida que se conserva la velocidad angular, el objeto producido debe mantener la misma velocidad angular que tenía en el momento del lanzamiento: `objectAngularVelocity = throwingControllerAngularVelocity;`</span><span class="sxs-lookup"><span data-stu-id="6966b-159">As angular velocity is conserved, the thrown object must maintain the same angular velocity as it had at the moment of the throw: `objectAngularVelocity = throwingControllerAngularVelocity;`</span></span>
   2. <span data-ttu-id="6966b-160">Dado que es probable que el centro de la masa del objeto iniciado no sea el origen de la representación del puño, es probable que tenga una velocidad distinta a la del controlador en el marco de referencia del usuario.</span><span class="sxs-lookup"><span data-stu-id="6966b-160">As the center of mass of the thrown object is likely not at the origin of the grip pose, it likely has a different velocity than that of the controller in the frame of reference of the user.</span></span> <span data-ttu-id="6966b-161">La parte de la velocidad del objeto aportada de esta manera es la velocidad tangencial instantánea del centro de la masa del objeto producido en torno al origen del controlador.</span><span class="sxs-lookup"><span data-stu-id="6966b-161">The portion of the object’s velocity contributed in this way is the instantaneous tangential velocity of the center of mass of the thrown object around the controller origin.</span></span> <span data-ttu-id="6966b-162">Esta velocidad tangencial es el producto cruzado de la velocidad angular del controlador con el vector que representa la distancia entre el origen del controlador y el centro de la masa del objeto iniciado.</span><span class="sxs-lookup"><span data-stu-id="6966b-162">This tangential velocity is the cross product of the angular velocity of the controller with the vector representing the distance between the controller origin and the center of mass of the thrown object.</span></span>

      ```cs
      Vector3 radialVec = thrownObjectCenterOfMass - throwingControllerPos;
      Vector3 tangentialVelocity = Vector3.Cross(throwingControllerAngularVelocity, radialVec);
      ```

   3. <span data-ttu-id="6966b-163">La velocidad total del objeto generado es la suma de la velocidad del controlador y esta velocidad tangencial: `objectVelocity = throwingControllerVelocity + tangentialVelocity;`</span><span class="sxs-lookup"><span data-stu-id="6966b-163">The total velocity of the thrown object is the sum of velocity of the controller and this tangential velocity: `objectVelocity = throwingControllerVelocity + tangentialVelocity;`</span></span>

* <span data-ttu-id="6966b-164">**Preste mucha atención a la *hora* a la que se aplica la velocidad**.</span><span class="sxs-lookup"><span data-stu-id="6966b-164">**Pay close attention to the *time* at which we apply the velocity**.</span></span> <span data-ttu-id="6966b-165">Cuando se presiona un botón, puede tardar hasta 20 ms para ese evento en pasar a través de Bluetooth al sistema operativo.</span><span class="sxs-lookup"><span data-stu-id="6966b-165">When a button is pressed, it can take up to 20 ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="6966b-166">Esto significa que, si sondea un cambio de estado del controlador de presionado a no presionado o viceversa, el controlador de la información de la forma que se obtiene se encuentra realmente por encima de este cambio en el estado.</span><span class="sxs-lookup"><span data-stu-id="6966b-166">This means that if you poll for a controller state change from pressed to not pressed or the other way around, the controller pose information you get with it will actually be ahead of this change in state.</span></span> <span data-ttu-id="6966b-167">Además, la causa del controlador presentada por nuestra API de sondeo se predice para reflejar una posible suposición en el momento en que se muestra el fotograma, lo que podría ser superior a 20 MS en el futuro.</span><span class="sxs-lookup"><span data-stu-id="6966b-167">Further, the controller pose presented by our polling API is forward predicted to reflect a likely pose at the time the frame will be displayed which could be more than 20 ms in the future.</span></span> <span data-ttu-id="6966b-168">Esto es adecuado para la *representación* de objetos retenidos, pero proporciona un problema de tiempo para el *objetivo* del objeto a medida que calculamos la trayectoria en el momento en que el usuario liberó el lanzamiento.</span><span class="sxs-lookup"><span data-stu-id="6966b-168">This is good for *rendering* held objects, but compounds our time problem for *targeting* the object as we calculate the trajectory for the moment the user released the throw.</span></span> <span data-ttu-id="6966b-169">Afortunadamente, con la actualización de noviembre, cuando se envía un evento de Unity, como *InteractionSourcePressed* o *InteractionSourceReleased* , el estado incluye los datos de la representación histórica al presionar o soltar el botón.</span><span class="sxs-lookup"><span data-stu-id="6966b-169">Fortunately, with the November update, when a Unity event like *InteractionSourcePressed* or *InteractionSourceReleased* is sent, the state includes the historical pose data from back when the button was pressed or released.</span></span>  <span data-ttu-id="6966b-170">Para obtener la representación del controlador y el destino del controlador más precisos durante las throws, debe usar correctamente el sondeo y los eventos, según corresponda:</span><span class="sxs-lookup"><span data-stu-id="6966b-170">To get the most accurate controller rendering and controller targeting during throws, you must correctly use polling and eventing, as appropriate:</span></span>
   * <span data-ttu-id="6966b-171">Para que el **controlador presente** cada fotograma, la aplicación debe colocar el *GameObject* del controlador en la representación del controlador de predicción para la hora de Photon del marco actual.</span><span class="sxs-lookup"><span data-stu-id="6966b-171">For **controller rendering** each frame, your app should position the controller's *GameObject* at the forward-predicted controller pose for the current frame’s photon time.</span></span>  <span data-ttu-id="6966b-172">Estos datos se obtienen de las API de sondeo de Unity como *[XR. InputTracking. GetLocalPosition](https://docs.unity3d.com/ScriptReference/XR.InputTracking.GetLocalPosition.html)* o *[XR. WSA. Input. InteractionManager. GetCurrentReading](https://docs.unity3d.com/ScriptReference/XR.WSA.Input.InteractionManager.GetCurrentReading.html)*.</span><span class="sxs-lookup"><span data-stu-id="6966b-172">You get this data from Unity polling APIs like *[XR.InputTracking.GetLocalPosition](https://docs.unity3d.com/ScriptReference/XR.InputTracking.GetLocalPosition.html)* or *[XR.WSA.Input.InteractionManager.GetCurrentReading](https://docs.unity3d.com/ScriptReference/XR.WSA.Input.InteractionManager.GetCurrentReading.html)*.</span></span>
   * <span data-ttu-id="6966b-173">En el caso de que el **controlador se dirija** a una imprenta o una versión, la aplicación debe Raycast y calcular las trayectorias en función de la suposición del controlador histórico para ese evento Press o Release.</span><span class="sxs-lookup"><span data-stu-id="6966b-173">For **controller targeting** upon a press or release, your app should raycast and calculate trajectories based on the historical controller pose for that press or release event.</span></span>  <span data-ttu-id="6966b-174">Estos datos se obtienen de las API de eventos de Unity, como *[InteractionManager. InteractionSourcePressed](https://docs.unity3d.com/ScriptReference/XR.WSA.Input.InteractionManager.InteractionSourcePressed.html)*.</span><span class="sxs-lookup"><span data-stu-id="6966b-174">You get this data from Unity eventing APIs, like *[InteractionManager.InteractionSourcePressed](https://docs.unity3d.com/ScriptReference/XR.WSA.Input.InteractionManager.InteractionSourcePressed.html)*.</span></span>
* <span data-ttu-id="6966b-175">**Utilice la postura de control**.</span><span class="sxs-lookup"><span data-stu-id="6966b-175">**Use the grip pose**.</span></span> <span data-ttu-id="6966b-176">La velocidad y la velocidad de angular se registran en relación con la pose de control, no con la función de puntero.</span><span class="sxs-lookup"><span data-stu-id="6966b-176">Angular velocity and velocity are reported relative to the grip pose, not pointer pose.</span></span>

<span data-ttu-id="6966b-177">El lanzamiento continuará mejorando con futuras actualizaciones de Windows y puede esperar encontrar más información aquí.</span><span class="sxs-lookup"><span data-stu-id="6966b-177">Throwing will continue to improve with future Windows updates, and you can expect to find more information on it here.</span></span>

## <a name="gesture-and-motion-controllers-in-mrtk-v2"></a><span data-ttu-id="6966b-178">Gestos y controladores de movimiento en MRTK V2</span><span class="sxs-lookup"><span data-stu-id="6966b-178">Gesture and Motion Controllers in MRTK v2</span></span>

<span data-ttu-id="6966b-179">Puede tener acceso al gesto y al controlador de movimiento desde el administrador de entrada.</span><span class="sxs-lookup"><span data-stu-id="6966b-179">You can access gesture and motion controller from the input Manager.</span></span>
* [<span data-ttu-id="6966b-180">Gesto en MRTK V2</span><span class="sxs-lookup"><span data-stu-id="6966b-180">Gesture in MRTK v2</span></span>](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Gestures.html)
* [<span data-ttu-id="6966b-181">Controlador de movimiento en MRTK V2</span><span class="sxs-lookup"><span data-stu-id="6966b-181">Motion Controller in MRTK v2</span></span>](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Controllers.html)


## <a name="follow-along-with-tutorials"></a><span data-ttu-id="6966b-182">Seguimiento de tutoriales</span><span class="sxs-lookup"><span data-stu-id="6966b-182">Follow along with tutorials</span></span>

<span data-ttu-id="6966b-183">Los tutoriales paso a paso, con ejemplos de personalización más detallados, están disponibles en la Academia de realidad mixta:</span><span class="sxs-lookup"><span data-stu-id="6966b-183">Step-by-step tutorials, with more detailed customization examples, are available in the Mixed Reality Academy:</span></span>

- [<span data-ttu-id="6966b-184">MR Input 211: gesto</span><span class="sxs-lookup"><span data-stu-id="6966b-184">MR Input 211: Gesture</span></span>](tutorials/holograms-211.md)
- [<span data-ttu-id="6966b-185">MR Input 213: controladores de movimiento</span><span class="sxs-lookup"><span data-stu-id="6966b-185">MR Input 213: Motion controllers</span></span>](../../deprecated/mixed-reality-213.md)

<span data-ttu-id="6966b-186">[![Entrada MR 213-controlador de movimiento](images/mr213-main-600px.jpg)](/windows/mixed-reality/mixed-reality-213)</span><span class="sxs-lookup"><span data-stu-id="6966b-186">[![MR Input 213 - Motion controller](images/mr213-main-600px.jpg)](/windows/mixed-reality/mixed-reality-213)</span></span><br>
<span data-ttu-id="6966b-187">*Entrada MR 213-controlador de movimiento*</span><span class="sxs-lookup"><span data-stu-id="6966b-187">*MR Input 213 - Motion controller*</span></span>

## <a name="next-development-checkpoint"></a><span data-ttu-id="6966b-188">Siguiente punto de control de desarrollo</span><span class="sxs-lookup"><span data-stu-id="6966b-188">Next Development Checkpoint</span></span>

<span data-ttu-id="6966b-189">Si está siguiendo el viaje de desarrollo de Unity que hemos diseñado, está a la mitad de explorar los bloques de creación principales de MRTK.</span><span class="sxs-lookup"><span data-stu-id="6966b-189">If you're following the Unity development journey we've laid out, you're in the midst of exploring the MRTK core building blocks.</span></span> <span data-ttu-id="6966b-190">Desde aquí, puede continuar con el siguiente bloque de compilación:</span><span class="sxs-lookup"><span data-stu-id="6966b-190">From here, you can continue to the next building block:</span></span>

> [!div class="nextstepaction"]
> [<span data-ttu-id="6966b-191">Seguimiento de manos y ocular</span><span class="sxs-lookup"><span data-stu-id="6966b-191">Hand and eye tracking</span></span>](./hand-eye-in-unity.md)

<span data-ttu-id="6966b-192">O bien puede saltar a las funcionalidades y las API de la plataforma de realidad mixta:</span><span class="sxs-lookup"><span data-stu-id="6966b-192">Or jump to Mixed Reality platform capabilities and APIs:</span></span>

> [!div class="nextstepaction"]
> [<span data-ttu-id="6966b-193">Experiencias compartidas</span><span class="sxs-lookup"><span data-stu-id="6966b-193">Shared experiences</span></span>](shared-experiences-in-unity.md)

<span data-ttu-id="6966b-194">Puede volver a los [puntos de control de desarrollo de Unity](unity-development-overview.md#2-core-building-blocks) en cualquier momento.</span><span class="sxs-lookup"><span data-stu-id="6966b-194">You can always go back to the [Unity development checkpoints](unity-development-overview.md#2-core-building-blocks) at any time.</span></span>

## <a name="see-also"></a><span data-ttu-id="6966b-195">Consulta también</span><span class="sxs-lookup"><span data-stu-id="6966b-195">See also</span></span>

* [<span data-ttu-id="6966b-196">Mirada-cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="6966b-196">Head-gaze and commit</span></span>](../../design/gaze-and-commit.md)
* [<span data-ttu-id="6966b-197">Controladores de movimiento</span><span class="sxs-lookup"><span data-stu-id="6966b-197">Motion controllers</span></span>](../../design/motion-controllers.md)